{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('criminal_df_v1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2723 entries, 0 to 2722\n",
      "Data columns (total 12 columns):\n",
      "Applicant         2722 non-null object\n",
      "Defendant         2720 non-null object\n",
      "Case No           2723 non-null object\n",
      "Judges            2723 non-null object\n",
      "Summary           2723 non-null object\n",
      "Date Heard        2072 non-null object\n",
      "Date Judgement    2318 non-null object\n",
      "Court             2723 non-null object\n",
      "Case Category     2723 non-null object\n",
      "Province          2723 non-null object\n",
      "Related Crimes    1470 non-null object\n",
      "Charge            2723 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 255.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace '\\\\'96'\n",
    "# to add bail, compensation amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Charge'] = df['Charge'].replace('theft', 'robbery')\n",
    "df['Charge'] = df['Charge'].replace('prescribed sentences', 'prescribed sentence')\n",
    "df['Charge'] = df['Charge'].replace('prescribed minimum sentences', 'prescribed sentence')\n",
    "df['Charge'] = df['Charge'].replace('housebreaking with intent to steal and theft', 'housebreaking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidence               396\n",
       "rape                   275\n",
       "arrest                 196\n",
       "murder                 177\n",
       "appeal                 171\n",
       "review                 127\n",
       "prescribed sentence    118\n",
       "robbery                110\n",
       "bail                    91\n",
       "damages                 56\n",
       "Name: Charge, dtype: int64"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Charge'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lack of information\n",
    "\n",
    "# remit\n",
    "# dismiss\n",
    "# inadmissible, common law position restored\n",
    "# set aside\n",
    "# appeal granted, appeal upheld\n",
    "\n",
    "# life sentence (25 years) and amount\n",
    "# prison sentence and amount\n",
    "# bail and amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemma_words(text):\n",
    "    \n",
    "    # returns clean text with infinitive verbs\n",
    "\n",
    "    blob = TextBlob(text)\n",
    "    blob_words = list(blob.words)\n",
    "    \n",
    "    blob_lst = []\n",
    "\n",
    "    for word in blob_words:\n",
    "        \n",
    "        new_word = lemma.lemmatize(word, 'v')\n",
    "\n",
    "        blob_lst.append(new_word)\n",
    "        \n",
    "    return ' '.join(blob_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_years(blob):\n",
    "\n",
    "    sentence_lst = []\n",
    "\n",
    "    # extract ngrams that include keywords like sentence, imprisonment and not old and age\n",
    "\n",
    "    for lst in blob.ngrams(3):\n",
    "        if 'years' in lst and ('old' not in lst and 'age' not in lst):\n",
    "            sentence_lst.append(list(lst))\n",
    "\n",
    "    concatted = []\n",
    "\n",
    "    for item in sentence_lst:     \n",
    "        concatted.append(' '.join(item))\n",
    "\n",
    "    concatted = ' '.join(concatted)\n",
    "    sentence_phrase = list(dict.fromkeys(concatted.split()))\n",
    "\n",
    "    # append ints that are mentioned in sentence_phrase \n",
    "\n",
    "    amount = []\n",
    "\n",
    "    for word in sentence_phrase:\n",
    "        try:\n",
    "            amount.append(int(word))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_amount(blob):\n",
    "    \n",
    "\n",
    "    amount_lst = []\n",
    "\n",
    "    # extract ngrams that include keywords like sentence, imprisonment and not old and age\n",
    "\n",
    "    for lst in blob.ngrams(3):\n",
    "        if 'years' in lst and ('old' not in lst and 'age' not in lst):\n",
    "            amount_lst.append(list(lst))\n",
    "\n",
    "    concatted = []\n",
    "\n",
    "    for item in sentence_lst:     \n",
    "        concatted.append(' '.join(item))\n",
    "\n",
    "    concatted = ' '.join(concatted)\n",
    "    sentence_phrase = list(dict.fromkeys(concatted.split()))\n",
    "\n",
    "    # append ints that are mentioned in sentence_phrase \n",
    "\n",
    "    amount = []\n",
    "\n",
    "    for word in sentence_phrase:\n",
    "        try:\n",
    "            amount.append(int(word))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verdict(text):\n",
    "    \n",
    "    text = text.replace('life sentence', '25 years sentence')\n",
    "    text = text.replace('sentenced to life', '25 years sentence')\n",
    "    text = text.replace('life imprisonment', '25 years sentence')\n",
    "    text = text.replace('life in prison', '25 years sentence')\n",
    "    \n",
    "    text = lemma_words(text)\n",
    "    \n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    blob_lst = blob.ngrams(4)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        amount = get_sentence_years(blob)\n",
    "        \n",
    "        for item in blob_lst:\n",
    "\n",
    "            if 'remit' in item:\n",
    "                verdict = 'Remitted'\n",
    "\n",
    "            elif 'inadmissible' in item or ('law' in item and 'position' in item and 'restored' in item):\n",
    "                verdict = 'Inadmissible'\n",
    "\n",
    "            elif 'set' in item and 'aside' in item:\n",
    "                verdict = 'Set Aside'\n",
    "\n",
    "            elif 'uphold' in item and 'grant' in item:\n",
    "                verdict = 'Appeal Granted'\n",
    "\n",
    "            elif 'uphold' in item and 'appeal' in item:\n",
    "                verdict = 'Appeal Upheld'\n",
    "\n",
    "            elif 'appeal' in item and 'dismiss' in item:\n",
    "                verdict = 'Appeal Dismissed'\n",
    "\n",
    "            elif 'award' in item or 'compensate' in item or 'compensation' in item:\n",
    "                verdict = 'Compensation'\n",
    "\n",
    "            elif 'suspend' in item and ('court' in item or 'sentence' in item):\n",
    "                verdict = 'Suspended'\n",
    "                \n",
    "            elif 'sentence' in item or 'imprisonment' in item:\n",
    "                verdict = 'Sentenced'\n",
    "                \n",
    "        return verdict, amount\n",
    "    \n",
    "    except UnboundLocalError:\n",
    "        return np.nan, amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Compensation', [])"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_verdict(df['Summary'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for words in text_test.split(' '):\n",
    "    try:\n",
    "        result =  re.search(\"^r+\", words) and re.search(\"\\d+\", words)\n",
    "        print(result.group())\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Verdict'] = df['Summary'].apply(get_verdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
